{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garyyu\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearningcpu\\lib\\site-packages\\tqdm\\autonotebook\\__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook,tnrange\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine title and body\n",
    "news_vip_v04[\"title_token_plus_body_token\"]=news_vip_v04[\"title_token\"]+\" \"+news_vip_v04[\"body_token\"]\n",
    "\n",
    "#clean token\n",
    "def CleanToken(string):\n",
    "    pattern=[re.compile(\"[\\)》\\，\\.\\、\\-\\%\\《\\(\\\"\\'\\％\\」\\「\\。\\（\\）\\；\\●：]\"),\n",
    "         re.compile(\"\\d\\d%\"),##EX: 85%\n",
    "         re.compile(\"\\d+\"),##EX:9,10,123..\n",
    "         re.compile(\" [a-zA-Z] \"),##EX: x , d ,...\n",
    "#          re.compile(\"[a-zA-Z]\"),\n",
    "        ]\n",
    "# string=trainset_vip[\"Title_and_body\"][7000]\n",
    "    for p in pattern:\n",
    "        string=p.sub(\" \",string)\n",
    "    string=re.sub(\"  +\",\" \",string)# two or above space to one space\n",
    "    string=re.sub(\"^ \",\"\",string)#space at beginning\n",
    "    string=re.sub(\" $\",\"\",string)#space at end\n",
    "    return string\n",
    "news_vip_v04[\"title_token_plus_body_token\"]=news_vip_v04[\"title_token_plus_body_token\"].progress_apply(CleanToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vectorize token to sparse bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer_keras(tokenizer,dim=70000):\n",
    "    tokenizer.num_words=dim\n",
    "    def do(text):\n",
    "        return sparse.csr_matrix(tokenizer.texts_to_matrix([text]).astype(np.int8).squeeze())\n",
    "    return do  \n",
    "\n",
    "sparsebow=News['title_token_plus_body_token'].progress_apply(vectorizer_keras(tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
